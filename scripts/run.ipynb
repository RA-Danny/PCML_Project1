{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning of data and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset, we can see that the 22th column is name **PRI_jet_num**. We consider that this is a type of test. Therefore, we split the dataset according to this value.\n",
    "\n",
    "This step will result in **4 matrices** of data, one for each value of the 22th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_sort, tX_sort, ids_sort = split_over_column(y, tX, ids, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new data, we perform two cleaning steps:\n",
    "<ul>\n",
    "    <li>\n",
    "        The rank of these matrices may be smaller than its size. We noticed that some columns have the same value for each row. Therefor we delete these columns, as they bring no value.\n",
    "    </li>\n",
    "    \n",
    "    <li>\n",
    "        In the data given, some cells have a value set to -999, meaning that a problem occured. In order to avoid the noise cause by this value, we decided to replace all -999 cells by the mean of the others values in the same column.\n",
    "    </li>\n",
    "    \n",
    "    <li>\n",
    "        After having remove the noise cause by -999 values, we standardize all columns.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cleaning \n",
    "tX_sort_clean = clean_unique_values_columns(tX_sort)\n",
    "tX_stand = remove_and_standardize(tX_sort_clean)\n",
    "\n",
    "column_to_remove = [[10],[14],[6],[11]]\n",
    "tX_clean = remove_column(tX_stand,column_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.263929223086\n"
     ]
    }
   ],
   "source": [
    "best_degrees = [11,11,9,9]\n",
    "best_lambdas = [0.00024,0.000043,0.0012, 0.0005]\n",
    "\n",
    "weights = []\n",
    "mean_mse = []\n",
    "for i in range(0,4):\n",
    "    x_tr = tX_clean[i]\n",
    "    x_train_poly = build_poly(x_tr,best_degrees[i])\n",
    "    mse_train,w = ridge_regression(y_sort[i],x_train_poly, best_lambdas[i])\n",
    "    weights.append(w)\n",
    "    mean_mse.append(mse_train)\n",
    "    \n",
    "mse = np.mean(mean_mse)\n",
    "print(\"mean\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_sort, tX_sort, ids_sort = split_over_column(y_test, tX_test, ids_test, 22)\n",
    "tX_sort_clean = clean_unique_values_columns(tX_sort)\n",
    "tX_stand = remove_and_standardize(tX_sort_clean)\n",
    "tX_clean = remove_column(tX_stand,column_to_remove)\n",
    "\n",
    "y_pred_all = []\n",
    "for i in range(len(weights)):\n",
    "    w = weights[i]\n",
    "    tX_test_clean_poly = build_poly(tX_clean[i], best_degrees[i])\n",
    "    y_pred = predict_labels(w, tX_test_clean_poly)\n",
    "    y_pred_all.append(y_pred)\n",
    "    \n",
    "ids_test = np.concatenate(ids_sort).ravel()\n",
    "y_pred = np.concatenate(y_pred_all).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../submission.csv' #  fill in desired name of output file for submission\n",
    "#y_pred = predict_labels(weights, tX_test_clean_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
